{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "d0rVm3A62D7T"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "max_sequence_length = 10\n",
        "d_model = 6\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "even_i = torch.arange(0, d_model, 2).float()\n",
        "odd_i = torch.arange(1, d_model, 2).float()"
      ],
      "metadata": {
        "id": "n-lFNpQd2LVc"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "even_denominator = torch.pow(10000, even_i/d_model)\n",
        "odd_denominator = torch.pow(10000, (odd_i-1)/d_model)"
      ],
      "metadata": {
        "id": "VqHScm1s2Tgz"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "even_denominator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brTsbU4B7Xfa",
        "outputId": "85e38566-421f-488e-9972-11fcd7c1a375"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  1.0000,  21.5443, 464.1590])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "denominator = even_denominator"
      ],
      "metadata": {
        "id": "sHAn-WsB4s8w"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "position = torch.arange(max_sequence_length, dtype=torch.float).reshape(max_sequence_length, 1)"
      ],
      "metadata": {
        "id": "qXQ5QdcA45E2"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "position"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENeW5taq5ZXH",
        "outputId": "2948c185-faeb-49ea-d403-bcb6f11a772b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.],\n",
              "        [1.],\n",
              "        [2.],\n",
              "        [3.],\n",
              "        [4.],\n",
              "        [5.],\n",
              "        [6.],\n",
              "        [7.],\n",
              "        [8.],\n",
              "        [9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#position is of two types even position and odd position\n",
        "odd_position = torch.sin(position/odd_denominator)\n",
        "even_position = torch.cos(position/even_denominator)"
      ],
      "metadata": {
        "id": "H8L2dBP251xH"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "odd_position.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95a0u0eW6cS-",
        "outputId": "38e2d4c3-48ac-4d38-f59c-7cc1a961aaf2"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function Tensor.size>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "odd_position.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7_LYByc6muY",
        "outputId": "06d9cfdf-1a9a-400f-b2b0-daa7a8ddc7c5"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "odd_position"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opX_Vtci6fHk",
        "outputId": "5bc99c9f-269b-44c7-8d13-d2ca682c5f71"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.8415,  0.0464,  0.0022],\n",
              "        [ 0.9093,  0.0927,  0.0043],\n",
              "        [ 0.1411,  0.1388,  0.0065],\n",
              "        [-0.7568,  0.1846,  0.0086],\n",
              "        [-0.9589,  0.2300,  0.0108],\n",
              "        [-0.2794,  0.2749,  0.0129],\n",
              "        [ 0.6570,  0.3192,  0.0151],\n",
              "        [ 0.9894,  0.3629,  0.0172],\n",
              "        [ 0.4121,  0.4057,  0.0194]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "even_position"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckyGk3BD8h5D",
        "outputId": "c0239855-6471-4b72-871e-0fb6f23fb58d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.0000,  1.0000,  1.0000],\n",
              "        [ 0.5403,  0.9989,  1.0000],\n",
              "        [-0.4161,  0.9957,  1.0000],\n",
              "        [-0.9900,  0.9903,  1.0000],\n",
              "        [-0.6536,  0.9828,  1.0000],\n",
              "        [ 0.2837,  0.9732,  0.9999],\n",
              "        [ 0.9602,  0.9615,  0.9999],\n",
              "        [ 0.7539,  0.9477,  0.9999],\n",
              "        [-0.1455,  0.9318,  0.9999],\n",
              "        [-0.9111,  0.9140,  0.9998]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stack = torch.stack([even_position, odd_position], dim=1)"
      ],
      "metadata": {
        "id": "qTy7dGAf9x2R"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PE = torch.flatten(stack, start_dim=1, end_dim=2)\n",
        "PE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyouQnYZvzaT",
        "outputId": "3612d453-ff8a-40ad-922a-07a4abdc65d0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.0000,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.5403,  0.9989,  1.0000,  0.8415,  0.0464,  0.0022],\n",
              "        [-0.4161,  0.9957,  1.0000,  0.9093,  0.0927,  0.0043],\n",
              "        [-0.9900,  0.9903,  1.0000,  0.1411,  0.1388,  0.0065],\n",
              "        [-0.6536,  0.9828,  1.0000, -0.7568,  0.1846,  0.0086],\n",
              "        [ 0.2837,  0.9732,  0.9999, -0.9589,  0.2300,  0.0108],\n",
              "        [ 0.9602,  0.9615,  0.9999, -0.2794,  0.2749,  0.0129],\n",
              "        [ 0.7539,  0.9477,  0.9999,  0.6570,  0.3192,  0.0151],\n",
              "        [-0.1455,  0.9318,  0.9999,  0.9894,  0.3629,  0.0172],\n",
              "        [-0.9111,  0.9140,  0.9998,  0.4121,  0.4057,  0.0194]])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    Positional encoding module for transformer architectures.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, max_sequence_length):\n",
        "        \"\"\"\n",
        "        Constructor method for PositionalEncoding class.\n",
        "\n",
        "        Args:\n",
        "            d_model (int): Dimensionality of the model.\n",
        "            max_sequence_length (int): Maximum sequence length.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self):\n",
        "        \"\"\"\n",
        "        Forward method to compute positional encoding.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Positional encoding tensor.\n",
        "        \"\"\"\n",
        "        # Calculate even indices\n",
        "        even_i = torch.arange(0, self.d_model, 2).float()\n",
        "        # Calculate denominators\n",
        "        denominator = torch.pow(10000, even_i/self.d_model)\n",
        "        # Create position tensor\n",
        "        position = torch.arange(self.max_sequence_length).reshape(self.max_sequence_length, 1)\n",
        "        # Calculate even positional encoding\n",
        "        even_PE = torch.sin(position / denominator)\n",
        "        # Calculate odd positional encoding\n",
        "        odd_PE = torch.cos(position / denominator)\n",
        "        # Stack even and odd encodings\n",
        "        stacked = torch.stack([even_PE, odd_PE], dim=2)\n",
        "        # Flatten the stacked tensor\n",
        "        PE = torch.flatten(stacked, start_dim=1, end_dim=2)\n",
        "        return PE\n",
        "\n",
        "# Create an instance of PositionalEncoding\n",
        "pe = PositionalEncoding(d_model=6, max_sequence_length=10)\n",
        "# Compute positional encoding\n",
        "pe.forward()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2hnmB--ieppf"
      }
    }
  ]
}